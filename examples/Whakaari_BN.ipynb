{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eruption forecasting with Bayesian Networks for Whakaari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a47bc420-11ce-4411-9251-aa0d635863ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "from collections.abc import Sequence, Callable\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import (LongitudeFormatter,\n",
    "                                   LatitudeFormatter)\n",
    "\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from whakaaribn import (load_all_whakaari_data,\n",
    "                        load_whakaari_catalogue,\n",
    "                        Discretizer,\n",
    "                        get_group_labels,\n",
    "                        pre_eruption_window,\n",
    "                        WhakaariModel,\n",
    "                        get_color,\n",
    "                        BayesNet,\n",
    "                        get_data)\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (roc_auc_score,\n",
    "                             log_loss,\n",
    "                             average_precision_score,\n",
    "                             auc)\n",
    "import tqdm as tqdm\n",
    "import xarray as xr\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37faf4",
   "metadata": {},
   "source": [
    "## Whakaari image and network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data directory to store figures and results\n",
    "data_dir = os.path.join(Path().resolve(), 'data')\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"creating \", data_dir)\n",
    "    os.makedirs(data_dir)\n",
    "else:\n",
    "    print(data_dir, \"already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9693213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = get_data('data/271912_Brad Scott_GNS Science.jpg')\n",
    "arr_img = plt.imread(fn, format='jpg')\n",
    "y, x, z = arr_img.shape\n",
    "factor=300\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax1 = fig.add_axes([0.02,0.525,0.5,0.45], projection=ccrs.Mercator())\n",
    "ax2 = fig.add_axes([0.48, 0.5, 0.51, 0.5])\n",
    "ax3 = fig.add_axes([0.1,0.05,0.4,0.4])\n",
    "ax4 = fig.add_axes([0.55,0.05,0.4,0.4])\n",
    "\n",
    "\n",
    "# Add a Map\n",
    "ax1.set_extent([160, 180, -49, -32], crs=ccrs.PlateCarree())\n",
    "ax1.coastlines(resolution='50m')\n",
    "ax1.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "ax1.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
    "url = \"https://basemaps.linz.govt.nz/v1/tiles/aerial/WebMercatorQuad/WMTSCapabilities.xml?api=c01jj05fc72acjxevhtrem76m80\"\n",
    "layer = \"aerial\"\n",
    "ax1.add_wmts(url, layer)\n",
    "\n",
    "label_style = {'color': 'black', 'weight': 'bold', 'size': 8}\n",
    "gl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                     linewidth=1, color='gray', alpha=0.5,\n",
    "                                     linestyle='--', xlabel_style=label_style,\n",
    "                                     ylabel_style=label_style)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlines = True\n",
    "gl.ylines = True\n",
    "gl.xlocator = mticker.FixedLocator([166, 172])\n",
    "gl.ylocator = mticker.FixedLocator([-45, -40, -35])\n",
    "gl.xformatter = LongitudeFormatter(direction_label=True)\n",
    "gl.yformatter = LatitudeFormatter(direction_label=True)\n",
    "gl.xpadding = -1\n",
    "gl.ypadding = -5\n",
    "ax1.plot(177.18270881065772, -37.51992819737241, marker='o', color='red',\n",
    "                  markersize=3, transform=ccrs.PlateCarree())\n",
    "ax1.text(\n",
    "    .1,\n",
    "    .9,\n",
    "    \"(A)\",\n",
    "    horizontalalignment=\"center\",\n",
    "    transform=ax1.transAxes,\n",
    "    fontdict={\"color\": \"k\", \"fontsize\": 14}\n",
    ")\n",
    "\n",
    "# Add an image of Whakaari\n",
    "ax2.imshow(arr_img)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.text(\n",
    "    .1,\n",
    "    .9,\n",
    "    \"(B)\",\n",
    "    horizontalalignment=\"center\",\n",
    "    transform=ax2.transAxes,\n",
    "    fontdict={\"color\": \"k\", \"fontsize\": 14}\n",
    ")\n",
    "\n",
    "# Add Network structure for causal model\n",
    "magma_edges = [('Magmatic Intrusion', 'Eruption'),\n",
    "               ('Magmatic Intrusion', 'Eqr'),\n",
    "               ('Magmatic Intrusion', 'RSAM'),\n",
    "               ('Magmatic Intrusion', 'SO2'),\n",
    "               ('Magmatic Intrusion', 'CO2'),\n",
    "               ('Magmatic Intrusion', 'H2S')]\n",
    "seal_edges = [('Hydrothermal Seal', 'Eruption'),\n",
    "              ('Hydrothermal Seal', 'Eqr'),\n",
    "              ('Hydrothermal Seal', 'RSAM'),\n",
    "              ('Hydrothermal Seal', 'SO2'),\n",
    "              ('Hydrothermal Seal', 'CO2'),\n",
    "              ('Hydrothermal Seal', 'H2S')]\n",
    "\n",
    "G1 = nx.DiGraph(magma_edges + seal_edges)\n",
    "\n",
    "G2 = nx.DiGraph([('Eruption', 'Eqr'),\n",
    "                 ('Eruption', 'RSAM'),\n",
    "                 ('Eruption', 'SO2'),\n",
    "                 ('Eruption', 'CO2'),\n",
    "                 ('Eruption', 'H2S'),\n",
    "                 ('Eqr', 'RSAM'),\n",
    "                 ('Eqr', 'SO2'),\n",
    "                 ('Eqr', 'CO2'),\n",
    "                 ('Eqr', 'H2S'),\n",
    "                 ('RSAM', 'SO2'),\n",
    "                 ('RSAM', 'CO2'),\n",
    "                 ('RSAM', 'H2S'),\n",
    "                 ('CO2', 'SO2'),\n",
    "                 ('CO2', 'H2S'),\n",
    "                 ('SO2', 'H2S')])\n",
    "\n",
    "# group nodes by rows\n",
    "bottom_nodes = ['Magmatic Intrusion', 'Hydrothermal Seal']\n",
    "top_nodes = ['Eqr', 'RSAM', 'SO2', 'CO2', 'H2S']\n",
    "\n",
    "# set the position according to column (x-coord)\n",
    "x_pos_bottom = [0., 1.1]\n",
    "x_pos_top = [0., 0.35, 0.7, 1, 1.3]\n",
    "pos = {n: (_x, 0) for n, _x in zip(bottom_nodes, x_pos_bottom)}\n",
    "pos.update({n: (_x, .5) for n, _x in zip(top_nodes, x_pos_top)})\n",
    "pos.update({'Eruption': (-.3, 0.25)})\n",
    "pos = nx.spring_layout(G1, pos=pos)\n",
    "pos.update({'Magmatic Intrusion': (-.3, 0.25)})\n",
    "pos.update({'Hydrothermal Seal': (.3, -0.25)})\n",
    "\n",
    "arrowsize = 14\n",
    "nx.draw_networkx_edges(G1, pos, edgelist=magma_edges,\n",
    "                       edge_color='r', ax= ax3,\n",
    "                       arrowsize=arrowsize)\n",
    "nx.draw_networkx_edges(G1, pos, edgelist=seal_edges,\n",
    "                       edge_color='b', ax= ax3,\n",
    "                       arrowsize=arrowsize)\n",
    "\n",
    "label_options = {\"fc\": \"white\", \"alpha\": 0.5}\n",
    "nx.draw_networkx_labels(G1, pos, font_size=12, ax=ax3, bbox=label_options, verticalalignment='center')\n",
    "nx.draw_networkx_nodes(G1, pos, ax= ax3)\n",
    "\n",
    "ax3.axis(\"off\")\n",
    "ax3.text(\n",
    "    0.1,\n",
    "    0.9,\n",
    "    \"(C)\",\n",
    "    horizontalalignment=\"center\",\n",
    "    transform=ax3.transAxes,\n",
    "    fontdict={\"color\": \"k\", \"fontsize\": 14}\n",
    ")\n",
    "\n",
    "# Add network structure for fully-connected model\n",
    "pos = nx.kamada_kawai_layout(G2)\n",
    "nx.draw_networkx_edges(G2, pos, ax= ax4, arrowsize=arrowsize)\n",
    "nx.draw_networkx_nodes(G2, pos, ax= ax4)\n",
    "label_options = {\"fc\": \"white\", \"alpha\": 0.5}\n",
    "nx.draw_networkx_labels(G2, pos, font_size=12, ax=ax4, bbox=label_options, verticalalignment='center')\n",
    "ax4.set_xlim(-1.2, 1.35)\n",
    "ax4.axis(\"off\")\n",
    "ax4.text(\n",
    "    0.05,\n",
    "    0.9,\n",
    "    \"(D)\",\n",
    "    horizontalalignment=\"center\",\n",
    "    transform=ax4.transAxes,\n",
    "    fontdict={\"color\": \"k\", \"fontsize\": 14}\n",
    ")\n",
    "fig.savefig('data/whakaari_island_and_graphs.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff3fd0",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf44dd9-b61f-40df-9ebd-9db26cdee652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_train_test_split(data, groups):\n",
    "    assert len(data) == len(groups)\n",
    "    data_ = pd.DataFrame(data.copy())\n",
    "    data_['group'] = groups\n",
    "    test_data = data_[data_['group']=='d']\n",
    "    remainder = data_[data_['group']=='e']\n",
    "    train_data = data_.drop(data_[data_.group == 'd'].index)\n",
    "    train_data = train_data.drop(train_data[data_.group == 'e'].index)\n",
    "    \n",
    "    test = test_data.drop(columns=['group'])\n",
    "    train = train_data.drop(columns=['group'])\n",
    "    remainder = remainder.drop(columns=['group'])\n",
    "    return train, test, remainder\n",
    "    \n",
    "data = load_all_whakaari_data(fill_method=None, startdate=datetime(2009, 1, 1),\n",
    "                              enddate=datetime(2024, 9, 10),\n",
    "                              ignore_data=('LP', 'VLP'), ignore_cache=True,\n",
    "                              ignore_all_caches=True, fuse_so2=False)\n",
    "\n",
    "\n",
    "def get_train_test_data(data, ndays=30, min_interval=360, min_size=2):\n",
    "    groups=get_group_labels(data.index[0], data.index[-1], ndays=ndays,\n",
    "                            min_interval=min_interval, min_size=min_size)\n",
    "    X_train, X_test, X_remainder = group_train_test_split(data, groups)\n",
    "    eruptions = load_whakaari_catalogue(min_size, '0D')\n",
    "    dfe = eruptions.loc[data.index[0]:]\n",
    "    dates = pd.date_range(data.index[0], data.index[-1], freq='1D')\n",
    "    dfe = dfe.reindex(dates, fill_value=0)\n",
    "    dfe.drop(['delta', 'tvalue'], axis=1, inplace=True)\n",
    "    y_train, y_test, y_remainder = group_train_test_split(np.sign(dfe['Activity_Scale']), groups)\n",
    "    return X_train, X_test, X_remainder, y_train, y_test, y_remainder, groups\n",
    "\n",
    "\n",
    "X_train, X_test, X_remainder, y_train, y_test, y_remainder, groups = get_train_test_data(data)\n",
    "\n",
    "assert y_train.shape[0] + y_test.shape[0] == X_train.shape[0] + X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2428b54",
   "metadata": {},
   "source": [
    "## Data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f01be-1e5a-47d2-9867-885332afed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=11, cols=1, shared_xaxes=True, vertical_spacing=0.02,\n",
    "                    specs=[[{}], \n",
    "                           [{\"rowspan\": 2, \"secondary_y\": True}],\n",
    "                           [{}], \n",
    "                           [{\"rowspan\": 2, \"secondary_y\": True}],\n",
    "                           [{}],\n",
    "                           [{\"rowspan\": 2, \"secondary_y\": True}], \n",
    "                           [{}], \n",
    "                           [{\"rowspan\": 2, \"secondary_y\": True}],\n",
    "                           [{}],\n",
    "                           [{\"rowspan\": 2, \"secondary_y\": True}],\n",
    "                           [{}]],\n",
    "                    start_cell=\"bottom-left\")\n",
    "plot_dict = {'RSAM': dict(name='RSAM [nm/s]', mode='lines'),\n",
    "             'Eqr': dict(name='Eq. rate [1/day]', mode='lines'),\n",
    "             'CO2': dict(name=u'CO\\u2082 [t/day]', mode='markers'),\n",
    "             'SO2': dict(name=u'SO\\u2082 [t/day]', mode='markers'),\n",
    "             'H2S': dict(name=u'H\\u2082S [t/day]', mode='markers')}\n",
    "plot_data = data.assign(group=groups)\n",
    "plot_data = plot_data.assign(eruptions=pre_eruption_window(pd.concat([y_train, y_test, y_remainder]), 30))\n",
    "for i, g in enumerate(plot_data.groupby('group')):\n",
    "    fig.add_trace(go.Scatter(x=g[1].index, y=g[1]['eruptions'], mode='lines', line_color=get_color(i+2),\n",
    "                             showlegend=False, legendgroup='group1', legendgrouptitle_text='Data splits',\n",
    "                             name='Group %s' % g[0]), row=1, col=1)\n",
    "seismic_end_date = pd.Timestamp('2022-08-04')\n",
    "for i, col in enumerate(plot_dict.keys()):\n",
    "    showlegend = True\n",
    "    if i > 0:\n",
    "        showlegend = False\n",
    "    _x = plot_data.index\n",
    "    _y = plot_data[col].ffill()\n",
    "    _y_raw = plot_data[col]\n",
    "    if col in ['RSAM', 'Eqr']:\n",
    "        _x = _x[_x <= seismic_end_date]\n",
    "        _y = _y.iloc[:len(_x)]\n",
    "        _y_raw = plot_data[col].iloc[:len(_x)]\n",
    "    fig.add_trace(go.Scatter(x=_x, y=_y, mode='lines', line_color=get_color(1),\n",
    "                             showlegend=showlegend, name='Interpolated data', legendgroup='group',\n",
    "                             legendgrouptitle_text=\"Input data\"), row=i*2+2, col=1, secondary_y=False)\n",
    "    color = get_color(0)\n",
    "    if plot_dict[col]['mode'] == 'markers':\n",
    "        color = get_color(0, alpha=0.7)\n",
    "    fig.add_trace(go.Scatter(x=_x, y=_y_raw, mode=plot_dict[col]['mode'],\n",
    "                             showlegend=showlegend, name='Raw data', legendgroup='group',\n",
    "                             legendgrouptitle_text=\"Input data\", line_color=color), row=i*2+2, col=1,\n",
    "                    secondary_y=False)\n",
    "    \n",
    "    fig.update_yaxes(title=plot_dict[col]['name'], row=i*2+2, col=1, secondary_y=False)\n",
    "if True:\n",
    "    eruptions = load_whakaari_catalogue(2, '0D')\n",
    "    dfe_ = eruptions.loc[\"2004-01-01\":]\n",
    "    showlegend = True \n",
    "    for row in [2, 4, 6, 8, 10]:\n",
    "        for i in range(len(dfe_.index)):\n",
    "            fig.add_trace(go.Scatter(x=[dfe_.index[i], dfe_.index[i]], y=[0., 1.], mode='lines',\n",
    "                                     line_width=.8, line_color='black', name='Observed eruption', \n",
    "                                     showlegend=showlegend), secondary_y=True, row=row, col=1)\n",
    "            showlegend = False\n",
    "\n",
    "fig.update_layout(height=1000, width=1200)\n",
    "fig.update_layout(legend=dict(y=1.15, orientation='h'))\n",
    "fig.update_yaxes(type='log', nticks=3, secondary_y=False)\n",
    "fig.update_yaxes(type='linear', row=1, col=1)\n",
    "fig.update_yaxes(dtick=1, row=1, col=1)\n",
    "x_annot= \"2009-01-01\"\n",
    "y_annot = 0.9\n",
    "fig.add_annotation(text=\"<b>(F)</b>\", xref=\"x\", yref=\"y domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(E)</b>\", xref=\"x\", yref=\"y2 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(D)</b>\", xref=\"x\", yref=\"y5 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(C)</b>\", xref=\"x\", yref=\"y8 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(B)</b>\", xref=\"x\", yref=\"y11 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(A)</b>\", xref=\"x\", yref=\"y14 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>Pre-eruption window</b>\", xref=\"x\", yref=\"y domain\", x=\"2010-09-01\", y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>Data groups:</b>\", xref=\"x\", yref=\"y domain\", x=\"2010-01-01\", y=.2, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>Group A</b>\", xref=\"x\", yref=\"y domain\", x=\"2011-10-01\", y=.2, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>Group B</b>\", xref=\"x\", yref=\"y domain\", x=\"2013-03-01\", y=.2, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>Group C</b>\", xref=\"x\", yref=\"y domain\", x=\"2015-06-01\", y=.2, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>Group D</b>\", xref=\"x\", yref=\"y domain\", x=\"2018-03-01\", y=.2, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>Group E</b>\", xref=\"x\", yref=\"y domain\", x=\"2022-02-01\", y=.2, showarrow=False)\n",
    "fig.update_yaxes(showticklabels=False, showgrid=False, secondary_y=True)\n",
    "fig.write_image('./data/dataset_plot_whakaari.png', height=1000, width=1200, scale=3)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec2e70b-a22f-4091-bd82-ac3a9bcfad30",
   "metadata": {},
   "source": [
    "## Forecasts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06a0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialGroupSplit:\n",
    "    def __init__(self, groups):\n",
    "        self.groups = groups\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        _data = X.copy()\n",
    "        conds = []\n",
    "        group_ids = np.unique(self.groups)\n",
    "        for i in range(group_ids[0:-1].size):\n",
    "            conds.append(f\"(self.groups == '{group_ids[i]}')\")\n",
    "            try:\n",
    "                _data_train = _data[eval('|'.join(conds))]\n",
    "            except KeyError as e:\n",
    "                print(conds)\n",
    "                raise e\n",
    "            train_idx0 = _data.index.get_indexer([_data_train.index[0]])[0]\n",
    "            train_idx1 = _data.index.get_indexer([_data_train.index[-1]])[0]\n",
    "            train = np.arange(train_idx0, train_idx1+1)\n",
    "            _data_test = _data[self.groups == group_ids[i+1]]\n",
    "            test_idx0 = _data.index.get_indexer([_data_test.index[0]])[0]\n",
    "            test_idx1 = _data.index.get_indexer([_data_test.index[-1]])[0]\n",
    "            test = np.arange(test_idx0, test_idx1+1)\n",
    "            yield train, test\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return np.unique(self.groups).size - 1\n",
    "\n",
    "\n",
    "def test_sequential_group_split():\n",
    "    groups = np.array(['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c', 'd', 'd', 'd'])\n",
    "    data = pd.DataFrame({'x': np.arange(groups.size)}, index=pd.date_range('2000-01-01', periods=groups.size))\n",
    "    sgs = SequentialGroupSplit(groups)\n",
    "    i = 1\n",
    "    for train, test in sgs.split(data):\n",
    "        assert train.size == i*3\n",
    "        assert test.size == 3\n",
    "        i += 1 \n",
    "    assert train.size == groups.size - 3\n",
    "    assert sgs.get_n_splits() == 3\n",
    "\n",
    "test_sequential_group_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2957e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecasts(data: pd.DataFrame, exclude_from_test: Sequence=(), pew: int=30, expert_only: bool=False, eq_sample_size: int=1,\n",
    "              modelfile: str='data/Whakaari_4s_initial1.xdsl', bins: tuple=(0, 5, 95, 100),\n",
    "              hidden_nodes: bool=True, uniformize: bool=False, randomize: bool=False, zarr_store='data/whakaari_forecasts.zarr',\n",
    "              recompute=False, save_trained_model=False, smoothing=None, ex_nodes=[]):\n",
    "    \"\"\"\n",
    "    Compute BN forecasts\n",
    "    \"\"\"\n",
    "    if zarr_store is not None:\n",
    "        group = \"/model={}/expert_only={}/bins={}/eq_sample_size={}/pew={}/exclude_from_test={}\".format(modelfile.replace('/', '_'), expert_only, str(bins),\n",
    "                                                        eq_sample_size, pew, exclude_from_test)\n",
    "        path = os.path.join(zarr_store, group[1:])\n",
    "        if os.path.isdir(path) and not recompute:\n",
    "            xds = xr.open_zarr(path, consolidated=False)\n",
    "            print(f\"Loading forecasts from {path}\")\n",
    "            return xds\n",
    "    data_fill = data.ffill(axis=0)\n",
    "    data_fill.loc['2022-07-01':, 'RSAM'] = np.nan\n",
    "    data_fill.loc['2022-07-01':, 'Eqr'] = np.nan\n",
    "    pipe = Pipeline([('discretize', Discretizer(bins=bins, strategy='quantile', names=None)),\n",
    "                     ('clf', WhakaariModel(expert_only=expert_only, uniformize=uniformize, eq_sample_size=eq_sample_size,\n",
    "                                          randomize=randomize, hidden_nodes=hidden_nodes,\n",
    "                                          modelfile=modelfile, smoothing=smoothing))])\n",
    "\n",
    "    x_train, x_test, x_remainder, y_train, y_test, y_remainder, groups = get_train_test_data(data_fill, ndays=30)\n",
    "    y_train = pre_eruption_window(y_train, pew)\n",
    "    y_test = pre_eruption_window(y_test, pew)\n",
    "    y_all = pd.concat([y_train, y_test, y_remainder])\n",
    "    cv = SequentialGroupSplit(groups) \n",
    "    probs = np.zeros(data_fill.shape[0])\n",
    "    magma = np.zeros(data_fill.shape[0])\n",
    "    seal = np.zeros(data_fill.shape[0])\n",
    "    sens = np.zeros(data_fill.shape)\n",
    "    disc_data = np.full(data_fill.shape, '*', dtype='<U7')\n",
    "    init = True\n",
    "    for train, test in cv.split(data_fill):\n",
    "        pipe.fit(data_fill.iloc[train], y_all.iloc[train])\n",
    "        if init:\n",
    "            probs[train] = pipe.predict_proba(data_fill.iloc[train])[:, 1]\n",
    "            magma[train] = pipe['clf'].hidden_proba_[:, 1]\n",
    "            seal[train] = pipe['clf'].hidden_proba_[:, 3]\n",
    "            init = False\n",
    "        _data_test = data_fill.copy()\n",
    "        for col in exclude_from_test:\n",
    "            _data_test[col] = np.nan\n",
    "        probs[test] = pipe.predict_proba(_data_test.iloc[test])[:, 1]\n",
    "        magma[test] = pipe['clf'].hidden_proba_[:, 1]\n",
    "        seal[test] = pipe['clf'].hidden_proba_[:, 3]\n",
    "        _sens = pd.DataFrame(pipe.score(_data_test.iloc[test]))\n",
    "        sens[test, :] = _sens.values[:]\n",
    "        disc_data[test, :] = pipe[:-1].transform(data_fill.iloc[test])\n",
    "    if save_trained_model:\n",
    "        trained_modelfile = modelfile.replace('.xdsl', '_trained.xdsl')\n",
    "        pipe['clf'].net_.write(trained_modelfile)\n",
    "        datafile = modelfile.replace('.xdsl', '_data.csv')\n",
    "        pd.DataFrame(data=disc_data, index=data_fill.index, columns=data_fill.columns).to_csv(datafile)\n",
    "\n",
    "    xds = xr.Dataset(\n",
    "        {\n",
    "            \"probs\": ([\"time\"], probs),\n",
    "            \"probs_min\": ([\"time\"], probs),\n",
    "            \"probs_max\": ([\"time\"], probs),\n",
    "            \"magma\": ([\"time\"], magma),\n",
    "            \"magma_min\": ([\"time\"], magma),\n",
    "            \"magma_max\": ([\"time\"], magma),\n",
    "            \"seal\": ([\"time\"], seal),\n",
    "            \"seal_min\": ([\"time\"], seal),\n",
    "            \"seal_max\": ([\"time\"], seal),\n",
    "            \"sens\": ([\"time\", \"type\"], sens),\n",
    "            \"original_data\": ([\"time\", \"type\"], data.values),\n",
    "            \"discrete_data\": ([\"time\", \"type\"], disc_data),\n",
    "            \"y_all\": ([\"time\"], y_all.values.squeeze())\n",
    "        },\n",
    "        coords={\"time\": data.index.tz_localize(None),\n",
    "                \"type\": data.columns.astype(str)},\n",
    "    )\n",
    "    if zarr_store is not None:\n",
    "        xds.to_zarr(zarr_store, group=group, mode='a')\n",
    "    return xds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12df73e0-e26b-4eb4-971c-c4adcf8570b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_plot(frcst, frcst_min=None, frcst_max=None, fig=None, ploterr=True, log=False, eruptions=True,\n",
    "                  label='Forecast', showlegend=True, color_id=0, alpha=1., window=30,\n",
    "                  row=1, col=1):\n",
    "    \"\"\"\n",
    "    Plot timeseries of forecast probabilities.\n",
    "    Arguments:\n",
    "    ----------\n",
    "        frcst: pandas.Dataframe \n",
    "            The forecast probabilities.\n",
    "        fig: plotly Figure, optional\n",
    "            The figure to add the plot to. If None, a new figure is created.\n",
    "        ploterr: bool, optional\n",
    "            Whether to plot error bounds of the forecast probabilities.\n",
    "        log: bool, optional\n",
    "            Whether to plot the y-axis on a log scale.\n",
    "        eruptions: bool, optional\n",
    "            Whether to plot the eruption times.\n",
    "        label: str, optional\n",
    "            The label of the forecast.\n",
    "        color_id: int, optional\n",
    "            The color of the forecast.\n",
    "        window: int, optional\n",
    "            The window size for the rolling mean.\n",
    "        row: int, optional\n",
    "            The row to add the plot to.\n",
    "        col: int, optional\n",
    "            The column to add the plot to.\n",
    "    Returns:\n",
    "    --------\n",
    "        fig: plotly Figure\n",
    "            The figure with the plot.\n",
    "\n",
    "    \"\"\"\n",
    "    if fig is None:\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    forecast = frcst\n",
    "    if window is not None:\n",
    "        forecast = frcst.rolling(dict(time=window)).mean()\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(forecast.time), y=forecast, mode='lines',\n",
    "                             line_color=get_color(color_id, alpha=alpha), name=label, showlegend=showlegend,\n",
    "                             legendgroup='group1'), row=row, col=col)\n",
    "    if ploterr:\n",
    "        fig.add_trace(go.Scatter(x=pd.to_datetime(frcst_min.time), y=frcst_min, mode='lines', marker=dict(color=\"#444\"),\n",
    "                                 line=dict(width=0), showlegend=False), row=row, col=col)\n",
    "        fig.add_trace(go.Scatter(x=pd.to_datetime(frcst_max.time), y=frcst_max, mode='lines', marker=dict(color=\"#444\"),\n",
    "                                 line=dict(width=0), showlegend=False, fillcolor=get_color(color_id, alpha=0.3),\n",
    "                                 fill='tonexty'), row=row, col=col)\n",
    "    if eruptions:\n",
    "        eruptions = load_whakaari_catalogue(1, '0D')\n",
    "        dfe = eruptions.loc[frcst.time[0].values:frcst.time[-1].values]\n",
    "        showlegend = showlegend \n",
    "        for i in range(len(dfe.index)):\n",
    "            fig.add_trace(go.Scatter(x=[dfe.index[i], dfe.index[i]], y=[0., 1.], mode='lines',\n",
    "                                     line_width=.8, line_color='black', name='Observed eruption', \n",
    "                                     showlegend=showlegend), secondary_y=True, row=row, col=col)\n",
    "            showlegend = False\n",
    "\n",
    "    if log:\n",
    "        fig.update_yaxes(type='log', secondary_y=False)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9cdaad-1d31-4149-9bf3-66ed90673bb8",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59527cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_node_positions(num_nodes, radius=200, offset=(200, 200)):\n",
    "    positions = []\n",
    "    for i in range(num_nodes):\n",
    "        theta = (2 * math.pi * i) / num_nodes\n",
    "        x = radius * math.cos(theta)\n",
    "        y = radius * math.sin(theta)\n",
    "        positions.append((int(x+offset[0]), int(y+offset[1])))\n",
    "    return positions\n",
    "\n",
    "def stacked_node_positions(num_causal_nodes, num_child_nodes, x_child=150,\n",
    "                           y_causal=200, y_child=100, node_distance=100):\n",
    "    \"\"\"\n",
    "    Create node positions for a stacked layout where causal nodes are at the top and child nodes at the bottom.\n",
    "    \"\"\"\n",
    "    x_causal = int((x_child + (num_child_nodes-1)*node_distance) / 2. - (num_causal_nodes-1)*node_distance / 2.)\n",
    "    positions = []\n",
    "    for i in range(num_causal_nodes):\n",
    "        positions.append((x_causal + i*node_distance, y_causal))\n",
    "    for i in range(num_child_nodes):\n",
    "        positions.append((x_child + i*node_distance, y_child))\n",
    "    return positions\n",
    "\n",
    "def fully_connected(nodes):\n",
    "    edges = []\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            edges.append((nodes[i], nodes[j]))\n",
    "    return edges\n",
    "\n",
    "def causal(causal_nodes, child_nodes):\n",
    "    edges = []\n",
    "    for i in range(len(child_nodes)):\n",
    "        for j in range(len(causal_nodes)):\n",
    "            edges.append((causal_nodes[j], child_nodes[i]))\n",
    "    return edges\n",
    "\n",
    "def create_network(network_file, node_names, positions, edges):\n",
    "    net_ = BayesNet()\n",
    "    for node, pos in zip(node_names, positions):\n",
    "        node_name, states = node\n",
    "        nstates = len(states) \n",
    "        node = net_.add_node(node_name, states, np.ones(nstates)/nstates, \n",
    "                             description=node_name, position=pos)\n",
    "    for parent, child in edges:\n",
    "        net_.add_arc(parent, child)\n",
    "    net_.write(network_file)\n",
    "\n",
    "for nstates in [2, 3, 4, 5]:\n",
    "    obs_states = [\"state_{:d}\".format(i) for i in range(nstates)]\n",
    "    binary_states = [\"no\", \"yes\"]\n",
    "    node_names = [('eruptions', binary_states), ('Eqr', obs_states),\n",
    "                  ('CO2', obs_states), ('RSAM', obs_states),\n",
    "                  ('SO2', obs_states), ('H2S', obs_states)]\n",
    "    causal_node_names = [('Magmatic_Intrusion', binary_states), ('Hydrothermal_Seal', binary_states)]\n",
    "    positions = circular_node_positions(len(node_names)) \n",
    "    causal_positions = stacked_node_positions(len(causal_node_names), len(node_names)) \n",
    "    edges = fully_connected([node for node, _ in node_names])\n",
    "    causal_edges = causal([node for node, _ in causal_node_names], [node for node, _ in node_names])\n",
    "    create_network(f\"data/fully_connected_model_{nstates}_states.xdsl\", node_names, positions, edges) \n",
    "    create_network(f\"data/causal_model_{nstates}_states.xdsl\", causal_node_names + node_names, causal_positions, causal_edges) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4da494",
   "metadata": {},
   "source": [
    "#### Validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d45dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_windows(starttime, endtime, pew):\n",
    "    \"\"\"\n",
    "    Get the evaluation windows for the forecasted rates.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "        starttime: pd.Timestamp\n",
    "            The start time of the forecast.\n",
    "        endtime: pd.Timestamp\n",
    "            The end time of the forecast.\n",
    "        pew: int\n",
    "            The pre-eruption window size.\n",
    "    Returns:\n",
    "    --------\n",
    "        positive_windows: list\n",
    "            The pre-eruption windows.\n",
    "        negative_windows: list\n",
    "            Non pre-eruption windows. \n",
    "    \"\"\"\n",
    "    explosive_eruptions = load_whakaari_catalogue(2, '0D')\n",
    "    explosive_eruptions = explosive_eruptions.loc[starttime:endtime]\n",
    "    positive_windows = []\n",
    "    negative_windows = []\n",
    "    tstart = starttime\n",
    "    for e in explosive_eruptions.iterrows():\n",
    "        positive_windows.append((e[0] - pd.Timedelta(days=pew-1), e[0]))\n",
    "        negative_windows.append((tstart, e[0] - pd.Timedelta(days=pew)))\n",
    "        tstart = e[0] + pd.Timedelta(days=30)\n",
    "    negative_windows.append((tstart, endtime))\n",
    "    return positive_windows, negative_windows\n",
    " \n",
    "def compute_rates(model: pd.DataFrame, pew: int, debug: bool=False):\n",
    "    \"\"\"\n",
    "    Compute the forecasted rates for positive and negative windows.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "        model: pandas.DataFrame\n",
    "            The model probabilities.\n",
    "        pew: int\n",
    "            The pre-eruption window size.\n",
    "        debug: bool, optional\n",
    "            Whether to print debug information.\n",
    "    Returns:\n",
    "    --------\n",
    "        dict: The forecasted rates for positive and negative windows as well as the overall rate.\n",
    "    \"\"\" \n",
    "    positive_windows, negative_windows = get_evaluation_windows(model.index[0], model.index[-1], pew)\n",
    "    positive_rates = []\n",
    "    for win_start, win_end in positive_windows:\n",
    "        tmp_model = model.loc[win_start:win_end]\n",
    "        rates = -np.log(1-tmp_model)\n",
    "        if debug:\n",
    "            print('--->', win_start, win_end, 'Forecasted rate:', rates)\n",
    "        positive_rates.append(rates)\n",
    "\n",
    "    negative_rates = []\n",
    "    for win_start, win_end in negative_windows:\n",
    "        tmp_model = model.loc[win_start:win_end]\n",
    "        rates = -np.log(1-tmp_model)\n",
    "        if debug:\n",
    "            print('--->', win_start, win_end, 'Forecasted rate:', rates)\n",
    "        negative_rates.append(rates)\n",
    "    positive_rates = np.concatenate(positive_rates)\n",
    "    negative_rates = np.concatenate(negative_rates)\n",
    "\n",
    "    yearly_scale = 365.25/pew\n",
    "    pos_mean = np.mean(positive_rates) * yearly_scale\n",
    "    pos_sem = np.std(positive_rates) / np.sqrt(len(positive_rates)) * yearly_scale\n",
    "    neg_mean = np.mean(negative_rates) * yearly_scale\n",
    "    neg_sem = np.std(negative_rates) / np.sqrt(len(negative_rates)) * yearly_scale\n",
    "    overall_rate = np.mean(-np.log(1-model)) * yearly_scale\n",
    "    overall_sem = np.std(-np.log(1-model)) / np.sqrt(len(model)) * yearly_scale\n",
    "   \n",
    "    return dict(positive_rates=(pos_mean, pos_sem), negative_rates=(neg_mean, neg_sem),\n",
    "                overall_rate=(overall_rate, overall_sem)) \n",
    "\n",
    "\n",
    "def evaluate_threshold(thresh: float, model: pd.DataFrame,\n",
    "                       debug: bool=False, pew: int=90,\n",
    "                       return_windows: bool=False):\n",
    "    \"\"\"\n",
    "    Evaluate the number of true positives, false positives, true negatives and false negatives for a given threshold.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "        thresh: float\n",
    "            The threshold value.\n",
    "        model: pandas.DataFrame\n",
    "            The forecasted probabilities.\n",
    "        debug: bool, optional\n",
    "            Whether to print debug information.\n",
    "        pew: int, optional\n",
    "            The pre-eruption window size.\n",
    "        return_windows: bool, optional\n",
    "            Whether to return the positive and negative windows.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        dict: The evaluation results.\n",
    "        list: A list of dictionaries for the tp, fp, tn, fn windows.\n",
    "    \"\"\"\n",
    "    starttime = max(pd.Timestamp(model.index[0]), pd.Timestamp('2013-01-01'))\n",
    "    endtime = pd.Timestamp(model.index[-1])\n",
    "    explosive_eruptions = load_whakaari_catalogue(2, '0D')\n",
    "    explosive_eruptions = explosive_eruptions.loc[starttime:endtime]\n",
    "    if debug:\n",
    "        print(explosive_eruptions)\n",
    "    model = model.loc[starttime:endtime]\n",
    "    # normalise to 0-1\n",
    "    model = (model - model.min()) / (model.max() - model.min())\n",
    "    dt = pd.to_datetime(model.index)\n",
    "    bin_model = np.where(model >= thresh, 1, 0)\n",
    "    if len(bin_model.shape) > 1:\n",
    "        bin_model = bin_model[0]\n",
    "    # assign data on eruption days to the value on the day before \n",
    "    eidx = np.where(np.isin(model.index, explosive_eruptions.index))[0]\n",
    "    bin_model[eidx] = bin_model[eidx - 1] \n",
    "    negative_windows = []\n",
    "    positive_windows = []\n",
    "    first_day = 0\n",
    "    alert = bin_model[0]\n",
    "    for i, date in enumerate(dt):\n",
    "        if bin_model[i] != alert or i == len(dt) - 1:\n",
    "            last_day = i - 1\n",
    "            if i == len(dt) - 1:\n",
    "                last_day = i\n",
    "            if alert > 0:\n",
    "                positive_windows.append((first_day, last_day))\n",
    "            else:\n",
    "                negative_windows.append((first_day, last_day))\n",
    "            first_day = i\n",
    "            alert = bin_model[i]\n",
    "\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    windows = []\n",
    "    if debug:\n",
    "        print('Positive windows:')\n",
    "    for win_start, win_end in positive_windows:\n",
    "        date_start = dt[win_start]\n",
    "        date_end = dt[win_end]\n",
    "        if debug:\n",
    "            print('--->', date_start, date_end)\n",
    "        explosion_in_window = False\n",
    "        for ee in explosive_eruptions.iterrows():\n",
    "            if date_start < ee[0] <= date_end:\n",
    "                if pew is not None:\n",
    "                    fp_ = tp_ = tn_ = fn_ = 0\n",
    "                    pre_eruption_window = ee[0] - pd.Timedelta(days=pew)\n",
    "                    tp_ += (date_end - ee[0]).days\n",
    "                    tp_ += (ee[0] - max(pre_eruption_window, date_start)).days\n",
    "                    pre_win = (date_start - pre_eruption_window).days\n",
    "                    if pre_win < 0:\n",
    "                        fp_ += abs(pre_win)\n",
    "                    else:\n",
    "                        fn_ += pre_win\n",
    "                    false_positives += fp_\n",
    "                    true_positives += tp_\n",
    "                    false_negatives += fn_\n",
    "                    # subtract from previous windows true_negatives\n",
    "                    true_negatives -= fn_\n",
    "                else:\n",
    "                    true_positives += (win_end - win_start + 1)\n",
    "                    windows.append(dict(start=date_start, end=date_end, type='true_positive'))\n",
    "                if debug:\n",
    "                    print('Eruption in positive window: ', date_start, date_end)\n",
    "                # stop if there is at least one eruption in the window\n",
    "                explosion_in_window = True\n",
    "                break\n",
    "        if not explosion_in_window:\n",
    "            false_positives += (win_end - win_start + 1)\n",
    "            windows.append(dict(start=date_start, end=date_end, type='false_positive'))\n",
    "\n",
    "    if debug:\n",
    "        print('Negative windows:')\n",
    "    for win_start, win_end in negative_windows:\n",
    "        date_start = dt[win_start]\n",
    "        date_end = dt[win_end]\n",
    "        if debug:\n",
    "            print('--->', date_start, date_end)\n",
    "        explosion_in_window = False\n",
    "        for ee in explosive_eruptions.iterrows():\n",
    "            if date_start < ee[0] <= date_end:\n",
    "                if pew is not None:\n",
    "                    fp_ = tp_ = tn_ = fn_ = 0\n",
    "                    tn_ = (date_end - ee[0]).days\n",
    "                    pre_eruption_window = ee[0] - pd.Timedelta(days=pew)\n",
    "                    fn_ = (ee[0] - max(pre_eruption_window, date_start)).days\n",
    "                    pre_win = (date_start - pre_eruption_window).days\n",
    "                    if pre_win < 0:\n",
    "                        tn_ += abs(pre_win)\n",
    "                    true_negatives += tn_\n",
    "                    false_negatives += fn_\n",
    "                else:\n",
    "                    false_negatives += (win_end - win_start + 1)\n",
    "                    # if window ends later than 09/01/2020 count the \n",
    "                    # days between that date and the window end date as true negatives\n",
    "                    # as the last explosive eruption was on 09/12/2019\n",
    "                    if date_end > pd.Timestamp('2020-01-09'):\n",
    "                        diff = (date_end - pd.Timestamp('2020-01-09')).days\n",
    "                        true_negatives += diff\n",
    "                        false_negatives -= diff\n",
    "                        windows.append(dict(start=date_start, end=date_end - pd.Timedelta(days=diff), type='false_negative'))\n",
    "                        windows.append(dict(start=date_end - pd.Timedelta(days=diff-1), end=date_end, type='true_negative'))\n",
    "                    else:\n",
    "                        windows.append(dict(start=date_start, end=date_end, type='false_negative'))\n",
    "                if debug:\n",
    "                    print('Eruption in negative window: ', date_start, date_end)\n",
    "                # stop if there is at least one eruption in the window\n",
    "                explosion_in_window = True \n",
    "                break\n",
    "        if not explosion_in_window:\n",
    "            true_negatives += (win_end - win_start + 1)\n",
    "            windows.append(dict(start=date_start, end=date_end, type='true_negative'))\n",
    "    if return_windows:\n",
    "        return dict(tp=true_positives, fp=false_positives, tn=true_negatives, fn=false_negatives), windows\n",
    "    return dict(tp=true_positives, fp=false_positives, tn=true_negatives, fn=false_negatives)\n",
    "\n",
    "def get_roc_curve(model: pd.DataFrame, thresholds: list, func: Callable,\n",
    "                  debug: bool=False):\n",
    "    \"\"\"\n",
    "    Compute the ROC curve for a given model and thresholds.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "        model: pandas.DataFrame\n",
    "            The model probabilities.\n",
    "        thresholds: list\n",
    "            The thresholds to evaluate.\n",
    "        func: function\n",
    "            The evaluation function.\n",
    "        debug: bool, optional\n",
    "            Whether to print debug information.\n",
    "    \"\"\"\n",
    "    tpr = np.empty(len(thresholds))*0.\n",
    "    fpr = np.empty(len(thresholds))*0.\n",
    "    precision = np.empty(len(thresholds))*0.\n",
    "\n",
    "    for i, thresh in enumerate(thresholds):\n",
    "        result = func(thresh, model)\n",
    "        if debug:\n",
    "            print(thresh, result)\n",
    "        try:\n",
    "            tpr_ = result['tp']/(result['tp'] + result['fn'])\n",
    "            fpr_ = result['fp']/(result['fp'] + result['tn'])\n",
    "            prec_ = result['tp']/(result['tp'] + result['fp'])\n",
    "        except ZeroDivisionError:\n",
    "            print(\"Threshold: \", thresh, \"True positives: \", result['tp'], \"False negatives: \", result['fn'])\n",
    "            print(\"Threshold: \", thresh, \"True negatives: \", result['tn'], \"False positives: \", result['fp'])\n",
    "            continue\n",
    "        # start the evaluation from the first correct alerts\n",
    "        if result['tp'] == 0:\n",
    "            continue\n",
    "        tpr[i] = tpr_\n",
    "        fpr[i] = fpr_\n",
    "        precision[i] = prec_\n",
    "    # make sure that tpr and fpr end in 1\n",
    "    # so that the AUC value is comparable\n",
    "    tpr = np.r_[tpr, 1.]\n",
    "    fpr = np.r_[fpr, 1.]\n",
    "    return tpr, fpr, precision\n",
    "\n",
    "\n",
    "def make_strictly_increasing(sequence: Sequence) -> Sequence:\n",
    "    \"\"\"\n",
    "    Make a sequence strictly increasing. Some of the ROC curves computed with\n",
    "    our own metric are not strictly increasing due to the way tps, fps, tns and fns\n",
    "    are defined. This function makes sure that the sequence is strictly increasing so\n",
    "    that we can caluculate the AUC value.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "        sequence: Sequence\n",
    "            The sequence to make strictly increasing.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        Sequence: The strictly increasing sequence.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original list\n",
    "    result = sequence\n",
    "    \n",
    "    # Iterate through the sequence starting from the second element\n",
    "    for i in range(1, len(result)):\n",
    "        # If the current element is not greater than the previous one\n",
    "        if result[i] <= result[i - 1]:\n",
    "            # Increment the current element to be greater than the previous one\n",
    "            result[i] = result[i - 1]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def test_make_strictly_increasing():\n",
    "    seq = [.1, .2, .3, .4, .2, .6, .7, .5, 1]\n",
    "    assert make_strictly_increasing(seq) == [.1, .2, .3, .4, .4, .6, .7, .7, 1]\n",
    "\n",
    "def test_evaluate_threshold():\n",
    "    test_seq = np.r_[np.ones(30)*.6, np.ones(30)*.2, np.ones(40)*.7]\n",
    "    dates = pd.date_range(pd.Timestamp('2013-10-21') - pd.Timedelta(days=100), periods=100)\n",
    "    test_df = pd.Series(data=test_seq, index=dates)\n",
    "    result, windows = evaluate_threshold(0.5, test_df, debug=False,\n",
    "                                         pew=None, return_windows=True)\n",
    "    assert result['tp'] == 40\n",
    "    assert result['fp'] == 30 \n",
    "    assert result['tn'] == 30\n",
    "    assert result['fn'] == 0\n",
    "    assert len(windows) == 3 \n",
    "    for win in windows:\n",
    "        if win['type'] == 'true_positive':\n",
    "            assert win['end'] == pd.Timestamp('2013-10-20')\n",
    "            assert (win['end'] - win['start']) == pd.Timedelta(days=39)\n",
    "\n",
    "    test_seq = np.r_[np.ones(30)*.7, np.ones(30)*.2, np.ones(40)*.4]\n",
    "    dates = pd.date_range(pd.Timestamp('2013-10-21') - pd.Timedelta(days=100), periods=100)\n",
    "    test_df = pd.Series(data=test_seq, index=dates)\n",
    "    result, windows = evaluate_threshold(0.5, test_df, debug=False,\n",
    "                                         pew=None, return_windows=True)\n",
    "    assert result['tp'] == 0\n",
    "    assert result['fp'] == 30 \n",
    "    assert result['tn'] == 0\n",
    "    assert result['fn'] == 70\n",
    "\n",
    "\n",
    "test_make_strictly_increasing()\n",
    "test_evaluate_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ecc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap(estimator, X, y, w=1):\n",
    "    prob_e = estimator.predict_proba(X)\n",
    "    weights = np.where(y == 1, w, 1)\n",
    "    score = average_precision_score(y, prob_e[:, 1], sample_weight=weights,\n",
    "                                    average='weighted')\n",
    "    return score \n",
    "\n",
    "def aic(estimator, X, y, dof=1):\n",
    "    \"\"\"\n",
    "    Akaike Information Criterion\n",
    "    \"\"\"\n",
    "    prob_e = estimator.predict_proba(X)\n",
    "    score = -2*log_loss(y, prob_e[:, 1])\n",
    "    score += 2*dof\n",
    "    return score\n",
    "\n",
    "def my_log_loss(estimator, X, y):\n",
    "    prob_e = estimator.predict_proba(X)\n",
    "    score = -log_loss(y, prob_e[:, 1])\n",
    "    return score\n",
    "\n",
    "def my_auc(estimator, X, y, w=1):\n",
    "    prob_e = estimator.predict_proba(X)\n",
    "    weights = np.where(y == 1, w, 1)\n",
    "    score = roc_auc_score(y, prob_e[:, 1], sample_weight=weights,\n",
    "                                    average='weighted')\n",
    "    return score \n",
    "\n",
    "def my_roc_auc(estimator, X, y, pew=90):\n",
    "    prob_e = estimator.predict_proba(X)\n",
    "    thresholds = np.linspace(0.01, 0.99, 100)[::-1]\n",
    "    mdl = pd.Series(prob_e[:, 1], index=X.index)\n",
    "    assert mdl.shape[0] > 0\n",
    "    tpr_bn, fpr_bn, precision_bn = get_roc_curve(mdl, thresholds, partial(evaluate_threshold, pew=pew))  \n",
    "    score = auc(make_strictly_increasing(fpr_bn), tpr_bn)\n",
    "    return score\n",
    "\n",
    "\n",
    "params_gcv = [\n",
    "    {   \"discretize__bins\": [(0, 5, 100), (0, 50, 100), (0, 95, 100)],\n",
    "        \"clf__hidden_nodes\": [False],\n",
    "        \"clf__uniformize\": [True],\n",
    "        \"clf__modelfile\": ['data/fully_connected_model_2_states.xdsl']\n",
    "    },\n",
    "     {   \"discretize__bins\": [(0, 5, 95, 100), (0, 33, 66, 100), (0, 25, 75, 100)],\n",
    "        \"clf__hidden_nodes\": [False],\n",
    "        \"clf__uniformize\": [True],\n",
    "        \"clf__modelfile\": ['data/fully_connected_model_3_states.xdsl']\n",
    "    },\n",
    "    {  \"discretize__bins\": [(0, 25, 50, 75, 100), (0, 5, 50, 95, 100), (0, 10, 50, 90, 100), (0, 20, 50, 80, 100)],\n",
    "        \"clf__hidden_nodes\": [False],\n",
    "        \"clf__uniformize\": [True],\n",
    "        \"clf__modelfile\": ['data/fully_connected_model_4_states.xdsl']\n",
    "    },\n",
    "    {  \"discretize__bins\": [(0, 20, 40, 60, 80, 100), (0, 5, 20, 80, 95, 100), (0, 5, 25, 75, 95, 100)],\n",
    "        \"clf__hidden_nodes\": [False],\n",
    "        \"clf__uniformize\": [True],\n",
    "        \"clf__modelfile\": ['data/fully_connected_model_5_states.xdsl']\n",
    "    }\n",
    "]\n",
    "\n",
    "whmdl = WhakaariModel(modelfile='data/Whakaari_bn_start.xdsl', uniformize=False, randomize=False,\n",
    "                      hidden_nodes=True, smoothing=30)\n",
    "pipe = Pipeline([('discretize', Discretizer(strategy='quantile', names=None)),\n",
    "                 ('clf', whmdl)])\n",
    "\n",
    "pipe.set_output(transform=\"pandas\")\n",
    "cv = SequentialGroupSplit(groups[groups != 'e'])\n",
    "\n",
    "search_results = {}\n",
    "for pew in np.arange(10, 110, 10):\n",
    "    search_results[pew] = {}\n",
    "    print(\"Pre-eruption window = \", pew)\n",
    "    for nstates, params in zip([2, 3, 4, 5], params_gcv):\n",
    "        print(\"Number of states = \", nstates)\n",
    "        dof = np.sum(2*nstates**np.arange(1,6))\n",
    "        _y_train = pre_eruption_window(y_train, pew)\n",
    "        y_test = pre_eruption_window(y_test, pew)\n",
    "        search = GridSearchCV(estimator=pipe, param_grid=[params],\n",
    "                              scoring={'average_precision': partial(ap, w=1),\n",
    "                                    'aic': partial(aic, dof=dof),\n",
    "                                    'log_loss': my_log_loss,\n",
    "                                    'roc_auc': partial(my_auc, w=1),\n",
    "                                    'mod_roc_auc': partial(my_roc_auc, pew=pew),\n",
    "                                    'mod_roc_auc_no_pew': partial(my_roc_auc, pew=None)},\n",
    "                              cv=cv, n_jobs=10, verbose=1, refit=False)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "            search.fit(pd.concat((X_train, X_test)).ffill(), pd.concat((_y_train, y_test)))\n",
    "        sdf = pd.DataFrame(search.cv_results_)\n",
    "        sdf = sdf.sort_values(by=['rank_test_mod_roc_auc_no_pew'])\n",
    "        search_results[pew][nstates] = sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add82bf",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b51e2-3b37-42e8-bd90-8249d3c7bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pew = np.arange(10, 110, 10)\n",
    "nstates = np.arange(2, 6)\n",
    "metric = 'mod_roc_auc_no_pew'\n",
    "data_types = ['RSAM', 'Eqr', 'CO2', 'SO2', 'H2S']\n",
    "smooth_win = 30\n",
    "fig = make_subplots(rows=2, cols=1, specs=[[{\"secondary_y\": True}], \n",
    "                                           [{\"secondary_y\": True}]], shared_xaxes=True)\n",
    "\n",
    "sdf_tmp = search_results[pew[0]][nstates[0]]\n",
    "sdf_tmp = sdf_tmp.sort_values(by=[f'rank_test_{metric}'])\n",
    "estimator = sdf_tmp.iloc[0].params\n",
    "xds = forecasts(pd.concat((X_train, X_test, X_remainder)), pew=pew[0], expert_only=False,\n",
    "                modelfile=estimator['clf__modelfile'],\n",
    "                bins=estimator['discretize__bins'],\n",
    "                hidden_nodes=estimator['clf__hidden_nodes'],\n",
    "                uniformize=estimator['clf__uniformize'],\n",
    "                randomize=False, zarr_store=None,\n",
    "                recompute=True, save_trained_model=False,\n",
    "                smoothing=30)\n",
    "\n",
    "forecast_plot(xds['probs'], fig=fig, log=False, ploterr=False,\n",
    "            eruptions=True, label='Forecast', showlegend=True, color_id=0, window=smooth_win, row=1, col=1)\n",
    "datatype = 'RSAM'\n",
    "df_data = xds['original_data'].loc[dict(type=datatype)].to_pandas().fillna(method='ffill')\n",
    "df_data_disc = xds['discrete_data'].loc[dict(type=datatype)].to_pandas()\n",
    "fig.add_trace(go.Scatter(name=datatype, x=df_data.index, y=df_data, mode='lines', line_color=get_color(7)), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(name=\"%s_disc\" % datatype, x=df_data_disc.index,\n",
    "                        y=np.unique(df_data_disc, return_inverse=True)[1],\n",
    "                        mode='lines', line_color=get_color(7, alpha=.5)), row=2, col=1, secondary_y=True)\n",
    "fig.update_layout(height=600)\n",
    "fig.update_xaxes(showticklabels=True, row=2, col=1)\n",
    "\n",
    "figw = go.FigureWidget(fig)\n",
    "dataset = widgets.Dropdown(\n",
    "    options=list(data_types),\n",
    "    value=data_types[0],\n",
    "    description='Dataset:',\n",
    ")\n",
    "\n",
    "states = widgets.Dropdown(\n",
    "    options=list(nstates),\n",
    "    value=nstates[0],\n",
    "    description='States:',\n",
    ")\n",
    "\n",
    "prewin = widgets.Dropdown(\n",
    "    options=list(pew),\n",
    "    value=pew[0],\n",
    "    description='Pre-eruption window:',\n",
    ")\n",
    "\n",
    "\n",
    "def response(change):\n",
    "    with figw.batch_update():\n",
    "        sdf_tmp = search_results[prewin.value][states.value]\n",
    "        sdf_tmp = sdf_tmp.sort_values(by=[f'rank_test_{metric}'])\n",
    "        estimator = sdf_tmp.iloc[0].params\n",
    "        xds = forecasts(pd.concat((X_train, X_test, X_remainder)), pew=prewin.value, expert_only=False,\n",
    "                        modelfile=estimator['clf__modelfile'],\n",
    "                        bins=estimator['discretize__bins'],\n",
    "                        hidden_nodes=estimator['clf__hidden_nodes'],\n",
    "                        uniformize=estimator['clf__uniformize'],\n",
    "                        randomize=False, zarr_store=None,\n",
    "                        recompute=True, save_trained_model=False,\n",
    "                        smoothing=30)\n",
    "\n",
    "        _df_data = xds['original_data'].to_pandas().fillna(method='ffill')\n",
    "        _df_disc_data = xds['discrete_data'].to_pandas()\n",
    "        for i in range(len(figw.data)):\n",
    "            if figw.data[i].name == 'Forecast':\n",
    "                figw.data[i].y = xds['probs']\n",
    "                figw.data[i].x = pd.to_datetime(xds['probs']['time'])\n",
    "            for node_name in data_types:\n",
    "                if figw.data[i].name == \"%s_disc\" % node_name:\n",
    "                    figw.data[i].y = np.unique(_df_disc_data[dataset.value], return_inverse=True)[1]\n",
    "                    figw.data[i].x = _df_disc_data.index\n",
    "                    figw.data[i].name = \"%s_disc\" % dataset.value \n",
    "                if figw.data[i].name == node_name:\n",
    "                    figw.data[i].y = _df_data[dataset.value]\n",
    "                    figw.data[i].x = _df_data.index \n",
    "                    figw.data[i].name = dataset.value \n",
    "\n",
    "\n",
    "dataset.observe(response, names='value')\n",
    "states.observe(response, names='value')\n",
    "prewin.observe(response, names='value')\n",
    "\n",
    "widgets.VBox([widgets.HBox([dataset, states, prewin]), figw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5447677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(search_results, pews, nstates, exclude_from_test=()):\n",
    "    best_objective = -np.inf\n",
    "    best_pew = pews[0]\n",
    "    for _ns in nstates:\n",
    "        for _pew in pews:\n",
    "            sdf_tmp = search_results[_pew][_ns]\n",
    "            sdf_tmp = sdf_tmp.sort_values(by=['rank_test_mod_roc_auc_no_pew'])\n",
    "            if sdf_tmp.iloc[0].mean_test_mod_roc_auc_no_pew > best_objective:\n",
    "                best_objective = sdf_tmp.iloc[0].mean_test_mod_roc_auc_no_pew\n",
    "                best_estimator = sdf_tmp.iloc[0].params\n",
    "                best_pew = _pew\n",
    "    xds = forecasts(pd.concat((X_train, X_test, X_remainder)), pew=best_pew,\n",
    "                    expert_only=False, exclude_from_test=exclude_from_test,\n",
    "                    modelfile=best_estimator['clf__modelfile'],\n",
    "                    bins=best_estimator['discretize__bins'],\n",
    "                    hidden_nodes=best_estimator['clf__hidden_nodes'],\n",
    "                    uniformize=best_estimator['clf__uniformize'],\n",
    "                    randomize=False, zarr_store='data/best_model.zarr',\n",
    "                    recompute=True, save_trained_model=False,\n",
    "                    smoothing=30)\n",
    "    return xds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f05d9e",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c886c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_plot(fcst: pd.Series, threshold: float, showlegend: bool=False,\n",
    "                    debug: bool=False, fig=None, row: int=1, col: int=1):\n",
    "    \"\"\"\n",
    "    Plot the forecast probabilities and the evaluation windows.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "        fcst: pandas.DataFrame\n",
    "            The forecast probabilities.\n",
    "        threshold: float\n",
    "            The threshold value.\n",
    "        debug: bool, optional\n",
    "            Whether to print debug information.\n",
    "        fig: plotly Figure, optional\n",
    "            The figure to add the plot to. If None, a new figure is created.\n",
    "        row: int, optional\n",
    "            The row to add the plot to.\n",
    "        col: int, optional\n",
    "            The column to add the plot to.\n",
    "    \"\"\"\n",
    "    trace = (fcst - fcst.min())/(fcst.max() - fcst.min())\n",
    "    time = trace.index\n",
    "    stats_, time_windows = evaluate_threshold(threshold, trace, pew=None, return_windows=True)\n",
    "    if debug:\n",
    "        print(stats_)\n",
    "    if fig is None:\n",
    "        fig = make_subplots(rows=1, cols=1, specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    eruptions = load_whakaari_catalogue(2, '0D')\n",
    "    eruptions = eruptions.loc['2013':'2020']\n",
    "    showlegend = showlegend \n",
    "    for i in range(len(eruptions.index)):\n",
    "        fig.add_trace(go.Scatter(x=[eruptions.index[i], eruptions.index[i]], y=[0., .7], mode='lines',\n",
    "                                    line_width=.8, line_color='black', name='Observed Eruption', \n",
    "                                    showlegend=showlegend), secondary_y=False, row=row, col=col)\n",
    "        showlegend = False\n",
    "    cl_ = dict(true_positive=get_color(0), true_negative=get_color(2), false_positive=get_color(1), false_negative=get_color(3))\n",
    "    for window in time_windows:\n",
    "        start = window[\"start\"]\n",
    "        end = window[\"end\"]\n",
    "        type_ = window[\"type\"]\n",
    "        \n",
    "        # Mask the time series within the current window\n",
    "        mask = (time >= start) & (time <= end)\n",
    "        x_window = time[mask]\n",
    "        y_window = trace[mask]\n",
    "        \n",
    "        # Choose color based on the type\n",
    "        color = cl_[type_] \n",
    "        \n",
    "        # Add a trace for the shaded area\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(x_window) + list(x_window[::-1]),  # x-coordinates for fill\n",
    "            y=list(y_window) + [threshold] * len(y_window),  # y-coordinates for fill\n",
    "            fill='toself',\n",
    "            fillcolor=color,\n",
    "            line=dict(color='rgba(255,255,255,0)'),  # No line around fill\n",
    "            hoverinfo='skip',\n",
    "            showlegend=False\n",
    "        ), row=row, col=col)\n",
    "    for type_, color in cl_.items():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None],  # Dummy x value\n",
    "            y=[None],  # Dummy y value\n",
    "            mode='markers',\n",
    "            marker=dict(size=10, color=color),\n",
    "            name=f\"{type_.capitalize()}\",\n",
    "            showlegend=showlegend\n",
    "        ), row=row, col=col)\n",
    "        \n",
    "    fig.update_yaxes(showticklabels=False, showgrid=False, secondary_y=True, row=row, col=col)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "329a98c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xds_best = get_best_model(search_results, np.arange(10, 110, 10), np.arange(2, 6))\n",
    "tstart = \"2012-09-03\"\n",
    "tend = \"2022-09-10\"\n",
    "fcst = xds_best['probs'].to_pandas()\n",
    "fcst = fcst.loc[tstart:tend]\n",
    "thresholds = np.linspace(0.01, 0.99, 100)[::-1]\n",
    "tpr_bn, fpr_bn, precision_bn = get_roc_curve(xds_best['probs'].to_pandas(), thresholds, partial(evaluate_threshold, pew=None))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5427251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs = {}\n",
    "datatypes = ['RSAM', 'CO2', 'SO2', 'H2S']\n",
    "for _ds in datatypes:\n",
    "    _data = xds_best['original_data'].loc[dict(type=_ds)].to_pandas().loc[tstart:tend]\n",
    "    _data = _data.fillna(method='ffill')\n",
    "    tpr_, fpr_, prec_ = get_roc_curve(_data, thresholds, partial(evaluate_threshold, pew=None))\n",
    "    rocs[_ds] = dict(tpr=tpr_, fpr=fpr_, precision=prec_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62166367",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=4, cols=2, specs=[[{\"colspan\": 2, \"secondary_y\": True}, None], \n",
    "                                           [{\"colspan\": 2, \"secondary_y\": True}, None],\n",
    "                                           [{\"rowspan\": 2}, {\"rowspan\": 2}], [{}, {}]],\n",
    "                                           horizontal_spacing=0.1)\n",
    "\n",
    "validation_plot(xds_best['probs'].to_pandas(), 0.1, debug=False, fig=fig, row=1, col=1)\n",
    "validation_plot(xds_best['probs'].to_pandas(), 0.3, debug=False, fig=fig, row=2, col=1)\n",
    "fig.update_yaxes(tickvals=[.1, .3, .5], row=1, col=1)\n",
    "fig.update_yaxes(tickvals=[.1, .3, .5], row=2, col=1)\n",
    "fig.update_xaxes(range=[tstart, tend], row=1, col=1)\n",
    "fig.update_xaxes(range=[tstart, tend], row=2, col=1)\n",
    "fig.add_annotation(text=\"<b>(A)</b>\", xref=\"x domain\", yref=\"y domain\", x=.05, y=.9, showarrow=False, row=1, col=1)\n",
    "fig.add_annotation(text=\"<b>(B)</b>\", xref=\"x domain\", yref=\"y domain\", x=.05, y=.9, showarrow=False, row=2, col=1)\n",
    "# add legend manually\n",
    "fig.add_trace(go.Scatter(x=['2013-12-01'], y=[1, 1], mode='markers',\n",
    "                        showlegend=False, line_color=get_color(0)), row=1, col=1)\n",
    "fig.add_annotation(text=\"True Positives\", x='2014-01-01', y=1, showarrow=False, xanchor='left', row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=['2015-04-01'], y=[1, 1], mode='markers',\n",
    "                        showlegend=False, line_color=get_color(1)), row=1, col=1)\n",
    "fig.add_annotation(text=\"False Positives\", x='2015-05-01', y=1, showarrow=False, xanchor='left', row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=['2016-09-01'], y=[1, 1], mode='markers',\n",
    "                        showlegend=False, line_color=get_color(2)), row=1, col=1)\n",
    "fig.add_annotation(text=\"True Negatives\", x='2016-10-01', y=1, showarrow=False, xanchor='left', row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=['2018-03-01'], y=[1, 1], mode='markers',\n",
    "                        showlegend=False, line_color=get_color(3)), row=1, col=1)\n",
    "fig.add_annotation(text=\"False Negatives\", x='2018-04-01', y=1, showarrow=False, xanchor='left', row=1, col=1)\n",
    "\n",
    "for i, _ds in enumerate(datatypes):\n",
    "    fpr_, tpr_, prec_ = rocs[_ds]['fpr'], rocs[_ds]['tpr'], rocs[_ds]['precision']\n",
    "    fig.add_trace(go.Scatter(x=make_strictly_increasing(fpr_), y=tpr_, mode='lines', showlegend=False, line_color=get_color(i + 1)),\n",
    "                  row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=fpr_bn, y=tpr_bn, mode='lines', showlegend=False, line_color=get_color(0)), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', showlegend=False, line=dict(color='navy', dash='dash')), row=3, col=1)\n",
    "\n",
    "# add legend manually\n",
    "legend_x = 0.95\n",
    "legend_len = 0.1\n",
    "fig.add_trace(go.Scatter(x=[legend_x, legend_x + legend_len], y=[0.9, 0.9], mode='lines', showlegend=False, line_color=get_color(1)), row=3, col=1)\n",
    "fig.add_annotation(text=\"RSAM\", x=1.2, y=0.9, showarrow=False, row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=[legend_x, legend_x + legend_len], y=[0.8, 0.8], mode='lines', showlegend=False, line_color=get_color(2)), row=3, col=1)\n",
    "fig.add_annotation(text=u'CO\\u2082', x=1.2, y=0.8, showarrow=False, row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=[legend_x, legend_x + legend_len], y=[0.7, 0.7], mode='lines', showlegend=False, line_color=get_color(3)), row=3, col=1)\n",
    "fig.add_annotation(text=u'SO\\u2082', x=1.2, y=0.7, showarrow=False, row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=[legend_x, legend_x + legend_len], y=[0.6, 0.6], mode='lines', showlegend=False, line_color=get_color(4)), row=3, col=1)\n",
    "fig.add_annotation(text=u'H\\u2082S', x=1.2, y=0.6, showarrow=False, row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=[legend_x, legend_x + legend_len], y=[0.5, 0.5], mode='lines', showlegend=False, line_color=get_color(0)), row=3, col=1)\n",
    "fig.add_annotation(text=\"Bayesian Network\", x=1.3, y=0.5, showarrow=False, row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=[legend_x, legend_x + legend_len], y=[0.4, 0.4], mode='lines', showlegend=False, line=dict(color='navy', dash='dash')), row=3, col=1)\n",
    "fig.add_annotation(text=\"Random Classifier\", x=1.3, y=0.4, showarrow=False, row=3, col=1)\n",
    "fig.update_xaxes(tickvals=[0., 0.5, 1.], ticktext=[\"0\", \"0.5\", \"1\"], title='False positive rate', row=3, col=1)\n",
    "fig.update_yaxes(title='True positive rate', row=3, col=1)\n",
    "fig.add_annotation(text=\"<b>(C)</b>\", xref=\"x domain\", yref=\"y domain\", x=.95, y=.95, showarrow=False, row=3, col=1)\n",
    "\n",
    "\n",
    "# Warning times\n",
    "plot_tresh = []\n",
    "warning_times = []\n",
    "explosive_eruptions = load_whakaari_catalogue(2, '0D').loc[tstart:tend]\n",
    "for thresh in thresholds:\n",
    "    warning_time = np.empty(3)*np.nan\n",
    "    _ , time_windows = evaluate_threshold(thresh, fcst, pew=None, return_windows=True)\n",
    "    for w in time_windows:\n",
    "        if w['type'] == 'true_positive':\n",
    "            for i, e in enumerate(explosive_eruptions.iterrows()):\n",
    "                if w['start'] < e[0] <= w['end']:\n",
    "                    warning_time[i] = (e[0] - w['start']).days\n",
    "    warning_times.append(warning_time)\n",
    "    plot_tresh.append(thresh)\n",
    "warning_times = np.array(warning_times)\n",
    "fig.add_trace(go.Scatter(x=plot_tresh, y=warning_times[:,0], mode='lines', showlegend=False, line_color=get_color(1)), row=3, col=2)\n",
    "fig.add_trace(go.Scatter(x=plot_tresh, y=warning_times[:,1], mode='lines', showlegend=False, line_color=get_color(2)), row=3, col=2)\n",
    "fig.add_trace(go.Scatter(x=plot_tresh, y=warning_times[:,2], mode='lines', showlegend=False, line_color=get_color(3)), row=3, col=2)\n",
    "\n",
    "# Add legend manually\n",
    "fig.add_annotation(text='Eruptions',\n",
    "                   x=.19, y=70, showarrow=False, row=3, col=2)\n",
    "fig.add_trace(go.Scatter(x=[.15, .17], y=[60, 60], mode='lines', showlegend=False, line_color=get_color(1)), row=3, col=2)\n",
    "fig.add_annotation(text=explosive_eruptions.iloc[0].tvalue.strftime('%Y-%m-%d'),\n",
    "                   x=.2, y=60, showarrow=False, row=3, col=2)\n",
    "fig.add_trace(go.Scatter(x=[.15, .17], y=[50, 50], mode='lines', showlegend=False, line_color=get_color(2)), row=3, col=2)\n",
    "fig.add_annotation(text=explosive_eruptions.iloc[1].tvalue.strftime('%Y-%m-%d'),\n",
    "                   x=.2, y=50, showarrow=False, row=3, col=2)\n",
    "fig.add_trace(go.Scatter(x=[.15, .17], y=[40, 40], mode='lines', showlegend=False, line_color=get_color(3)), row=3, col=2)\n",
    "fig.add_annotation(text=explosive_eruptions.iloc[2].tvalue.strftime('%Y-%m-%d'),\n",
    "                   x=.2, y=40, showarrow=False, row=3, col=2)\n",
    "fig.add_annotation(text=\"<b>(D)</b>\", xref=\"x domain\", yref=\"y domain\", x=.95, y=.95, showarrow=False, row=3, col=2)\n",
    "\n",
    "fig.update_xaxes(range=[0.05, 0.25], title='Threshold', row=3, col=2)\n",
    "fig.update_yaxes(range=[0., 80], title='Warning time [days]', row=3, col=2)\n",
    "\n",
    "fig.update_layout(width=1000, height=600)\n",
    "fig.write_image('data/validation_plots.png', width=1000, height=600, scale=5)\n",
    "fig\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compute_rates(fcst, pew=40)\n",
    "print(res)\n",
    "print(res['positive_rates'][0] / res['negative_rates'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693844ef",
   "metadata": {},
   "source": [
    "### Forecast Trellis Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=4, cols=1, specs=[[{\"secondary_y\": True}], \n",
    "                                           [{\"secondary_y\": True}],\n",
    "                                           [{\"secondary_y\": True}],\n",
    "                                           [{\"secondary_y\": True}]])\n",
    "\n",
    "xds_best = get_best_model(search_results, np.arange(10, 110, 10), np.arange(2, 6))\n",
    "xds_best_seismic = get_best_model(search_results, np.arange(10, 110, 10), np.arange(2, 6),\n",
    "                                exclude_from_test=['SO2', 'H2S', 'CO2'])\n",
    "xds_best_gas = get_best_model(search_results, np.arange(10, 110, 10), np.arange(2, 6),\n",
    "                            exclude_from_test=['RSAM', 'Eqr'])\n",
    "\n",
    "showlegend = True\n",
    "eruptions = load_whakaari_catalogue(2, '0D')\n",
    "q_min = 0.15\n",
    "q_max = 0.85\n",
    "for irow, group_name in enumerate(['b', 'c', 'd', 'e']):\n",
    "    time = pd.to_datetime(xds_best['time'])[ groups == group_name]\n",
    "    probs_best = xds_best['probs'].values[groups == group_name]\n",
    "    fig.add_trace(go.Scatter(x=time, y=probs_best,\n",
    "                            mode='lines', name=\"Eruption Probability (best model)\",\n",
    "                            line_color=get_color(0), showlegend=showlegend),\n",
    "                            row=irow+1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(xds_best['time'])[groups == group_name],\n",
    "                            y=xds_best_gas['probs'].values[groups == group_name],\n",
    "                            mode='lines', name=\"Gas Eruption Probability\",\n",
    "                            line_color=get_color(3, alpha=0.5), showlegend=showlegend),\n",
    "                            row=irow+1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(xds_best['time'])[groups == group_name],\n",
    "                            y=xds_best_seismic['probs'].values[groups == group_name],\n",
    "                            mode='lines', name=\"Seismic Eruption Probability\",\n",
    "                            line_color=get_color(4, alpha=0.5), showlegend=showlegend),\n",
    "                            row=irow+1, col=1)\n",
    "    t1 = xds_best['time'][groups == group_name][0].values\n",
    "    t2 = xds_best['time'][groups == group_name][-1].values\n",
    "    dfe = eruptions.loc[t1:t2]\n",
    "    for i in range(len(dfe.index)):\n",
    "        fig.add_trace(go.Scatter(x=[dfe.index[i], dfe.index[i]], y=[0., 1.], mode='lines',\n",
    "                                line_width=.8, line_color='black', name='Explosive Eruption', \n",
    "                                showlegend=showlegend), secondary_y=True, row=irow + 1, col=1)\n",
    "        showlegend = False\n",
    "\n",
    "    indices = np.where(groups == group_name)[0]\n",
    "\n",
    "x_annot = 0.08\n",
    "y_annot = 0.9\n",
    "fig.add_annotation(text=\"<b>(A) Group B</b>\", xref=\"x domain\", yref=\"y domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(B) Group C</b>\", xref=\"x3 domain\", yref=\"y3 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(C) Group D</b>\", xref=\"x3 domain\", yref=\"y5 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(D) Group E</b>\", xref=\"x3 domain\", yref=\"y7 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "\n",
    "fig.add_annotation(text=\"Dome extrusion\", x=\"2012-11-24\", y=1.2, showarrow=False, yref='y domain')\n",
    "fig.add_vrect(\n",
    "    x0=\"2012-11-22\", x1=\"2012-12-10\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=1, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Geysering\", x=\"2013-02-15\", y=1.2, showarrow=False, yref='y domain')\n",
    "# Add shape regions\n",
    "fig.add_vrect(\n",
    "    x0=\"2013-01-15\", x1=\"2013-04-10\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=1, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Minor steam and mud eruptions\", x=\"2013-10-04\", y=1., showarrow=True, yref='y domain',\n",
    "                   xanchor='right')\n",
    "fig.add_annotation(x=\"2013-08-17\", y=1., showarrow=True, yref='y domain')\n",
    "fig.add_vrect(\n",
    "    x0=\"2013-08-15\", x1=\"2013-08-18\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=1, col=1)\n",
    "fig.add_vrect(\n",
    "    x0=\"2013-10-01\", x1=\"2013-10-08\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=1, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Banded tremor\", x=\"2015-10-13\", y=1.2, showarrow=False, yref='y3 domain', xref='x2')\n",
    "fig.add_vrect(\n",
    "    x0=\"2015-10-13\", x1=\"2015-10-20\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=2, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Non-explosive ash venting\", x=\"2016-09-13\", y=1.2, showarrow=False, yref='y5 domain', xref='x3')\n",
    "fig.add_vrect(\n",
    "    x0=\"2016-09-13\", x1=\"2016-09-18\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=3, col=1)\n",
    "\n",
    "\n",
    "fig.add_annotation(text=\"Earthquake swarm\", x=\"2019-06-15\", y=1.2, showarrow=False, yref='y5 domain', xref='x3')\n",
    "fig.add_vrect(\n",
    "    x0=\"2019-04-23\", x1=\"2019-07-01\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=3, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Minor ash emissions\", x=\"2019-12-24\", y=1.2, showarrow=False,\n",
    "                   arrowcolor=get_color(7), yref='y5 domain', xref='x3')\n",
    "fig.add_vrect(\n",
    "    x0=\"2019-12-23\", x1=\"2019-12-29\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=3, col=1)\n",
    "\n",
    "\n",
    "fig.add_annotation(text=\"Lava extrusion\", x=\"2020-01-15\", y=1.2, showarrow=False,\n",
    "                   arrowcolor=get_color(7), yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-01-10\", x1=\"2020-01-20\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "\n",
    "fig.add_annotation(text=\"Minor ash emissions\", x=\"2020-11-13\", y=1.2, showarrow=False,\n",
    "                   arrowcolor=get_color(7), yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-11-13\", x1=\"2020-12-01\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "\n",
    "fig.add_annotation(text=\"Small steam explosions\", x=\"2020-12-29\", y=1.1, showarrow=False,\n",
    "                   xanchor='left', arrowcolor=get_color(7), yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-12-29\", x1=\"2021-01-02\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Minor ash emissions\", x=\"2022-09-18\", y=1.2, showarrow=False, yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2022-09-18\", x1=\"2022-09-24\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Small steam explosion\", x=\"2024-05-24\", y=1.2, showarrow=False,\n",
    "                   yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2024-05-24\", x1=\"2024-05-31\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Minor ash emissions\", x=\"2024-07-24\", y=1.1, showarrow=False,\n",
    "                   xanchor='left', yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2024-07-24\", x1=\"2024-09-10\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(width=1200, height=1000, legend=dict(y=1.1, orientation='h', font=dict(size=15)),)\n",
    "fig.update_yaxes(range=[0,1.2], row=5, col=1)\n",
    "fig.update_yaxes(showticklabels=False, showgrid=False, secondary_y=True)\n",
    "fig.update_xaxes(range=[\"2012-09-01\", \"2024-06-19\"], row=5, col=1)\n",
    "for _r in range(1, 5):\n",
    "    fig.update_xaxes(tickfont=dict(size=15), row=_r, col=1)\n",
    "    fig.update_yaxes(tickfont=dict(size=15), row=_r, col=1)\n",
    "fig.write_image('data/eruption_forecasts_whakaari.png', width=1200, height=1000, scale=5)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2be136",
   "metadata": {},
   "source": [
    "## Supplementary material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06763a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "metric = 'mod_roc_auc_no_pew'\n",
    "for nstates in [2, 3, 4, 5]:\n",
    "    vals = []\n",
    "    error = []\n",
    "    showlegend=True\n",
    "    for pew in search_results.keys():\n",
    "        sdf_tmp = search_results[pew][nstates] \n",
    "        sdf_tmp = sdf_tmp.sort_values(by=[f'rank_test_{metric}'])\n",
    "        vals.append(sdf_tmp.iloc[0][f'mean_test_{metric}'])\n",
    "        error.append(sdf_tmp.iloc[0][f'std_test_{metric}'])\n",
    "    vals = np.array(vals)\n",
    "    error = np.array(error)\n",
    "    fig.add_trace(go.Scatter(x=list(search_results.keys()), y=vals, mode='lines',\n",
    "                             name=f'{nstates} states', line_color=get_color(nstates-3)))\n",
    "    fig.add_trace(go.Scatter(x=list(search_results.keys()), y=vals+error, mode='lines', marker=dict(color=\"#444\"),\n",
    "                                 line=dict(width=0), showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=list(search_results.keys()), y=vals-error, mode='lines', marker=dict(color=\"#444\"),\n",
    "                                 line=dict(width=0), showlegend=False, fillcolor=get_color(nstates-3, alpha=0.1),\n",
    "                                 fill='tonexty'))\n",
    " \n",
    "fig.update_layout(title=\"Model objective function vs pre-eruption window\", xaxis_title=\"Pre-eruption window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncertainty estimates\n",
    "zarr_store = 'data/whakaari_forecasts.zarr'\n",
    "if False:\n",
    "    if os.path.isdir(zarr_store):\n",
    "        shutil.rmtree(zarr_store)\n",
    "fts = []\n",
    "fts_no_seismic = []\n",
    "fts_no_gas = []\n",
    "for nstates in np.arange(2, 6):\n",
    "    for pew in np.arange(10, 110, 10):\n",
    "        for _c in search_results[pew][nstates].iterrows():\n",
    "            if _c[1].mean_test_mod_roc_auc_no_pew < 0.85:\n",
    "                continue\n",
    "            _e = _c[1].params\n",
    "            xds = forecasts(pd.concat((X_train, X_test, X_remainder)), pew=pew, expert_only=False,\n",
    "                            modelfile=_e['clf__modelfile'],\n",
    "                            bins=_e['discretize__bins'],\n",
    "                            hidden_nodes=_e['clf__hidden_nodes'],\n",
    "                            uniformize=_e['clf__uniformize'],\n",
    "                            randomize=False, zarr_store=zarr_store,\n",
    "                            recompute=True, save_trained_model=False,\n",
    "                            smoothing=30)\n",
    "            xds_no_seismic = forecasts(pd.concat((X_train, X_test, X_remainder)),\n",
    "                                    pew=pew, expert_only=False,\n",
    "                                    exclude_from_test=('RSAM', 'Eqr'),\n",
    "                                    modelfile=_e['clf__modelfile'],\n",
    "                                    bins=_e['discretize__bins'],\n",
    "                                    hidden_nodes=_e['clf__hidden_nodes'],\n",
    "                                    uniformize=_e['clf__uniformize'],\n",
    "                                    randomize=False, zarr_store=zarr_store,\n",
    "                                    recompute=True, save_trained_model=False,\n",
    "                                    smoothing=30)\n",
    "            xds_no_gas = forecasts(pd.concat((X_train, X_test, X_remainder)),\n",
    "                                pew=pew, expert_only=False,\n",
    "                                exclude_from_test=('CO2', 'SO2', 'H2S'),\n",
    "                                modelfile=_e['clf__modelfile'],\n",
    "                                bins=_e['discretize__bins'],\n",
    "                                hidden_nodes=_e['clf__hidden_nodes'],\n",
    "                                uniformize=_e['clf__uniformize'],\n",
    "                                randomize=False, zarr_store=zarr_store,\n",
    "                                recompute=True, save_trained_model=False,\n",
    "                                smoothing=30)\n",
    "\n",
    "            fts.append(xds['probs'].values)\n",
    "            fts_no_seismic.append(xds_no_seismic['probs'].values)\n",
    "            fts_no_gas.append(xds_no_gas['probs'].values)\n",
    "xds_all = xr.DataArray(np.array(fts), dims=['model', 'time'], coords={'model': np.arange(len(fts)), 'time': xds['probs'].time})\n",
    "xds_all_no_seismic = xr.DataArray(np.array(fts_no_seismic), dims=['model', 'time'],\n",
    "                                  coords={'model': np.arange(len(fts_no_seismic)), 'time': xds_no_seismic['probs'].time})\n",
    "xds_all_no_gas = xr.DataArray(np.array(fts_no_gas), dims=['model', 'time'],\n",
    "                              coords={'model': np.arange(len(fts_no_gas)), 'time': xds_no_gas['probs'].time})\n",
    "\n",
    "group = f\"/ensemble_model/exclude_from_test=()\"\n",
    "xds_all.to_zarr(zarr_store, group=group, mode='a')\n",
    "group = f\"/ensemble_model/exclude_from_test=('RSAM', 'Eqr')\"\n",
    "xds_all_no_seismic.to_zarr(zarr_store, group=group, mode='a')\n",
    "group = f\"/ensemble_model/exclude_from_test=('CO2', 'SO2', 'H2S')\"\n",
    "xds_all_no_gas.to_zarr(zarr_store, group=group, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = f\"/ensemble_model/exclude_from_test=()\"\n",
    "zarr_store = 'data/whakaari_forecasts.zarr'\n",
    "xds1 = xr.open_zarr(zarr_store, group=model1, consolidated=False).to_array()\n",
    "xds_best = get_best_model(search_results, np.arange(10, 110, 10), np.arange(2, 6))\n",
    "fig = make_subplots(rows=4, cols=1, specs=[[{\"secondary_y\": True}], \n",
    "                                           [{\"secondary_y\": True}],\n",
    "                                           [{\"secondary_y\": True}],\n",
    "                                           [{\"secondary_y\": True}]])\n",
    "showlegend = True\n",
    "eruptions = load_whakaari_catalogue(1, '0D')\n",
    "cump = np.full(xds1.shape[-1], np.nan)\n",
    "q_min = 0.15\n",
    "q_max = 0.85\n",
    "for irow, group_name in enumerate(['b', 'c', 'd', 'e']):\n",
    "    time = pd.to_datetime(xds1['time'])[ groups == group_name]\n",
    "    probs_median = xds1.median('model').values[0, groups == group_name]\n",
    "    probs_best = xds_best['probs'].values[groups == group_name]\n",
    "    probs_min = xds1.chunk(dict(model=-1)).quantile(q_min, 'model').values[0, groups == group_name]\n",
    "    probs_max = xds1.chunk(dict(model=-1)).quantile(q_max, 'model').values[0, groups == group_name]\n",
    "    fig.add_trace(go.Scatter(x=time, y=probs_median,\n",
    "                             mode='lines', name=\"Eruption Probability (median model)\",\n",
    "                             line_color=get_color(0), showlegend=showlegend),\n",
    "                             row=irow+1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=time, y=probs_best,\n",
    "                             mode='lines', name=\"Eruption Probability (best model)\",\n",
    "                             line_dash='dash',\n",
    "                             line_color=get_color(0), showlegend=showlegend),\n",
    "                             row=irow+1, col=1)\n",
    "    if True:\n",
    "        fig.add_trace(go.Scatter(x=time, y=probs_min,\n",
    "                                mode='lines', marker=dict(color=\"#444\"),\n",
    "                                line=dict(width=0), showlegend=False), row=irow+1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=time, y=probs_max,\n",
    "                                mode='lines', marker=dict(color=\"#444\"),\n",
    "                                line=dict(width=0), showlegend=False, fillcolor=get_color(0, alpha=0.3),\n",
    "                                fill='tonexty'), row=irow+1, col=1)\n",
    " \n",
    "    t1 = xds1['time'][groups == group_name][0].values\n",
    "    t2 = xds1['time'][groups == group_name][-1].values\n",
    "    dfe = eruptions.loc[t1:t2]\n",
    "    for i in range(len(dfe.index)):\n",
    "        fig.add_trace(go.Scatter(x=[dfe.index[i], dfe.index[i]], y=[0., 1.], mode='lines',\n",
    "                                 line_width=.8, line_color='black', name='Observed Eruption', \n",
    "                                 showlegend=showlegend), secondary_y=True, row=irow + 1, col=1)\n",
    "        showlegend = False\n",
    "\n",
    "    indices = np.where(groups == group_name)[0]\n",
    "\n",
    "x_annot = 0.09\n",
    "y_annot = 0.9\n",
    "fig.add_annotation(text=\"<b>(A) Group B</b>\", xref=\"x domain\", yref=\"y domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(B) Group C</b>\", xref=\"x3 domain\", yref=\"y3 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(C) Group D</b>\", xref=\"x3 domain\", yref=\"y5 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "fig.add_annotation(text=\"<b>(D) Group E</b>\", xref=\"x3 domain\", yref=\"y7 domain\", x=x_annot, y=y_annot, showarrow=False)\n",
    "\n",
    "fig.add_annotation(text=\"Dome extrusion\", x=\"2012-11-24\", y=1.2, showarrow=False, yref='y domain')\n",
    "fig.add_vrect(\n",
    "    x0=\"2012-11-22\", x1=\"2012-12-10\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=1, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Geysering\", x=\"2013-02-15\", y=1.2, showarrow=False, yref='y domain')\n",
    "# Add shape regions\n",
    "fig.add_vrect(\n",
    "    x0=\"2013-01-15\", x1=\"2013-04-10\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=1, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Minor steam and mud eruptions\", x=\"2013-10-04\", y=1., showarrow=True, yref='y domain',\n",
    "                   xanchor='right')\n",
    "fig.add_annotation(x=\"2013-08-17\", y=1., showarrow=True, yref='y domain')\n",
    "fig.add_vrect(\n",
    "    x0=\"2013-08-15\", x1=\"2013-08-18\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=1, col=1)\n",
    "fig.add_vrect(\n",
    "    x0=\"2013-10-01\", x1=\"2013-10-08\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=1, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Banded tremor\", x=\"2015-10-13\", y=1.2, showarrow=False, yref='y3 domain', xref='x2')\n",
    "fig.add_vrect(\n",
    "    x0=\"2015-10-13\", x1=\"2015-10-20\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=2, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Non-explosive ash venting\", x=\"2016-09-13\", y=1.2, showarrow=False, yref='y5 domain', xref='x3')\n",
    "fig.add_vrect(\n",
    "    x0=\"2016-09-13\", x1=\"2016-09-18\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=3, col=1)\n",
    "\n",
    "\n",
    "fig.add_annotation(text=\"Earthquake swarm\", x=\"2019-06-15\", y=1.2, showarrow=False, yref='y5 domain', xref='x3')\n",
    "fig.add_vrect(\n",
    "    x0=\"2019-04-23\", x1=\"2019-07-01\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=3, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Minor ash emissions\", x=\"2019-12-24\", y=1.2, showarrow=False,\n",
    "                   arrowcolor=get_color(7), yref='y5 domain', xref='x3')\n",
    "fig.add_vrect(\n",
    "    x0=\"2019-12-23\", x1=\"2019-12-29\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=3, col=1)\n",
    "\n",
    "\n",
    "fig.add_annotation(text=\"Lava extrusion\", x=\"2020-01-15\", y=1.2, showarrow=False,\n",
    "                   arrowcolor=get_color(7), yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-01-10\", x1=\"2020-01-20\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "\n",
    "fig.add_annotation(text=\"Minor ash emissions\", x=\"2020-11-13\", y=1.2, showarrow=False,\n",
    "                   arrowcolor=get_color(7), yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-11-13\", x1=\"2020-12-01\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "\n",
    "fig.add_annotation(text=\"Small steam explosions\", x=\"2020-12-29\", y=1.1, showarrow=False,\n",
    "                   xanchor='left', arrowcolor=get_color(7), yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-12-29\", x1=\"2021-01-02\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Minor ash emissions\", x=\"2022-09-18\", y=1.2, showarrow=False, yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2022-09-18\", x1=\"2022-09-24\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Small steam explosion\", x=\"2024-05-24\", y=1.2, showarrow=False,\n",
    "                   yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2024-05-24\", x1=\"2024-05-31\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "fig.add_annotation(text=\"Minor ash emissions\", x=\"2024-07-24\", y=1.1, showarrow=False,\n",
    "                   xanchor='left', yref='y7 domain', xref='x4')\n",
    "fig.add_vrect(\n",
    "    x0=\"2024-07-24\", x1=\"2024-09-10\",\n",
    "    fillcolor=get_color(7), opacity=0.2,\n",
    "    layer=\"below\", line_width=0,\n",
    "    row=4, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(width=1200, height=1000, legend=dict(y=1.1, orientation='h', font=dict(size=15)),)\n",
    "fig.update_yaxes(range=[0,1.2], row=5, col=1)\n",
    "fig.update_yaxes(showticklabels=False, showgrid=False, secondary_y=True)\n",
    "fig.update_xaxes(range=[\"2012-09-01\", \"2024-06-19\"], row=5, col=1)\n",
    "for _r in range(1, 5):\n",
    "    fig.update_xaxes(tickfont=dict(size=15), row=_r, col=1)\n",
    "    fig.update_yaxes(tickfont=dict(size=15), row=_r, col=1)\n",
    "fig.write_image('data/eruption_forecast_uncertainties_whakaari.png', width=1200, height=1000, scale=5)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62808c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hindcasts(data: pd.DataFrame, exclude_from_test: Sequence=(), pew: int=30, expert_only: bool=False, eq_sample_size: int=1,\n",
    "              modelfile: str='data/Whakaari_4s_initial1.xdsl', bins: tuple=(0, 5, 95, 100),\n",
    "              hidden_nodes: bool=True, uniformize: bool=False, randomize: bool=False, zarr_store='data/whakaari_forecasts.zarr',\n",
    "              recompute=False, save_trained_model=False, smoothing=None, ex_nodes=[]):\n",
    "    \"\"\"\n",
    "    Compute BN hindcasts\n",
    "    \"\"\"\n",
    "    data_fill = data.ffill(axis=0)\n",
    "    data_fill.loc['2022-07-01':, 'RSAM'] = np.nan\n",
    "    data_fill.loc['2022-07-01':, 'Eqr'] = np.nan\n",
    "    pipe = Pipeline([('discretize', Discretizer(bins=bins, strategy='quantile', names=None)),\n",
    "                        ('clf', WhakaariModel(expert_only=expert_only, uniformize=uniformize, eq_sample_size=eq_sample_size,\n",
    "                                            randomize=randomize, hidden_nodes=hidden_nodes,\n",
    "                                            modelfile=modelfile, smoothing=smoothing))])\n",
    "\n",
    "    x_train, x_test, x_remainder, y_train, y_test, y_remainder, groups = get_train_test_data(data_fill, ndays=30)\n",
    "    y_train = pre_eruption_window(y_train, pew)\n",
    "    y_test = pre_eruption_window(y_test, pew)\n",
    "    y_all = pd.concat([y_train, y_test, y_remainder])\n",
    "    probs = np.zeros(data_fill.shape[0])\n",
    "    disc_data = np.full(data_fill.shape, '*', dtype='<U7')\n",
    "    pipe.fit(data_fill, y_all)\n",
    "    probs = pipe.predict_proba(data_fill)[:, 1]\n",
    "\n",
    "    xds = xr.Dataset(\n",
    "        {\n",
    "            \"probs\": ([\"time\"], probs),\n",
    "            \"probs_min\": ([\"time\"], probs),\n",
    "            \"probs_max\": ([\"time\"], probs),\n",
    "            \"original_data\": ([\"time\", \"type\"], data.values),\n",
    "            \"discrete_data\": ([\"time\", \"type\"], disc_data),\n",
    "            \"y_all\": ([\"time\"], y_all.values.squeeze())\n",
    "        },\n",
    "        coords={\"time\": data.index.tz_localize(None),\n",
    "                \"type\": data.columns.astype(str)},\n",
    "    )\n",
    "    return xds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a122276",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_objective = -np.inf\n",
    "pews = np.arange(10, 110, 10)\n",
    "nstates = np.arange(2, 6)\n",
    "for _ns in nstates:\n",
    "    for _pew in pews:\n",
    "        sdf_tmp = search_results[_pew][_ns]\n",
    "        sdf_tmp = sdf_tmp.sort_values(by=['rank_test_mod_roc_auc_no_pew'])\n",
    "        if sdf_tmp.iloc[0].mean_test_mod_roc_auc_no_pew > best_objective:\n",
    "            best_objective = sdf_tmp.iloc[0].mean_test_mod_roc_auc_no_pew\n",
    "            best_estimator = sdf_tmp.iloc[0].params\n",
    "            best_pew = _pew\n",
    "xds = hindcasts(pd.concat((X_train, X_test, X_remainder)), pew=best_pew,\n",
    "                expert_only=False, exclude_from_test=(),\n",
    "                modelfile=best_estimator['clf__modelfile'],\n",
    "                bins=best_estimator['discretize__bins'],\n",
    "                hidden_nodes=best_estimator['clf__hidden_nodes'],\n",
    "                uniformize=best_estimator['clf__uniformize'],\n",
    "                randomize=False, zarr_store=None,\n",
    "                recompute=True, save_trained_model=False,\n",
    "                smoothing=30)\n",
    "fig = forecast_plot(xds['probs'], log=False, ploterr=False, eruptions=True, label='Forecast', showlegend=True, color_id=0, window=1)\n",
    "fig.update_yaxes(showticklabels=False, showgrid=False, secondary_y=True)\n",
    "fig.write_image('data/hindcast_whakaari.png', width=1200, height=400, scale=5)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_rates(xds['probs'].to_pandas(), pew=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
